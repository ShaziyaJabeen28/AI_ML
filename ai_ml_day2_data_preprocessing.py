# -*- coding: utf-8 -*-
"""AI/ML_Day2_Data_preprocessing.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1x0ssLJgYt5YaBq6wP-0VQKQnt2tWPoDD
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

df=pd.read_csv('/content/pre_data.csv')
df

"""text cols are called categorical features.
NaN means missing data

These are the EDA process
"""

df.head()  #syntax:df.head(n) n: no of variables deafult first 5 rows

df.tail()  #syntax:df.tail(n) n: no of variables deafult last 5 rows

df.info()  #information aboy the dataset

df.describe() #returns the cols of the numerical value with their statistical Values

#starting the preprocessing task
#step1 : chacking for the null values

df.isnull() #check for the null values ,returns the full values

df.isnull().sum() #summarize the count of the above table

df.isna().sum()

#step2: (a) Handle the missing value
#we can use either imputation or dropping for the missing values
df2=df.copy()

# i) using droppinf method

df.dropna(inplace= True)   #deleting the rows with the null value using dropna()
df

# ii) using imputation
#sklearn is the library with machine learning algorithms (like pandas)
#we can also use fillna() to fill the null values

from sklearn.impute import SimpleImputer  #sklearn is package and SimpleImputer is the class in that package
#syntax: object=classname(parameter)
imputer= SimpleImputer(missing_values=np.nan, strategy='mean') #object creation of the class where to apply the object and what strategy to do in this method
imputer.fit(df2[['Age','Salary']])   #fit is used to get the mean and null value in a col
df2[['Age','Salary']] = imputer.transform(df2[['Age','Salary']]) # transform is used to tranform the null value with the mean value
df2

#(b) check duplicates

df2.duplicated().sum()

#Remove the duplicates

df2.drop_duplicates(inplace= True) #inplace=True is set, the method modifies the original DataFrame or Series object in place, without creating a new object.
df2

#(c) outliers : Values outside of the defined range , Eg: age exceeding to 180(incorrect) or -5 which is invalid value
#BoxPlot : it is used to check outliers


#Age
sns.boxplot(df2['Age'])

#Age has no outliers
#check salary
sns.boxplot(df2['Salary'])

#there is dot which means there is outliers
#handling the outliers
# Identify the quartiles
q1, q3 = np.percentile(df2['Salary'], [25, 75])
# Calculate the interquartile range
iqr = q3 - q1
# Calculate the lower and upper bounds
lower_bound = q1 - (1.5 * iqr)
upper_bound = q3 + (1.5 * iqr)
print(lower_bound, upper_bound)
# Drop the outliers
df2 = df2[(df2['Salary'] >= lower_bound)  & (df2['Salary'] <= upper_bound)]
df2

#(d) Label encoding : the process of converting labels into numeric form, labels with values b/w 0 and n_classes-1
from sklearn.preprocessing import LabelEncoder
le = LabelEncoder()
df2['Country']=le.fit_transform(df2['Country']) #fit and transform can be done in one
df2['Purchased']=le.fit_transform(df2['Purchased'])
df2

#(e) Feature Scaling/ Standardization/ Normalization
#reducing the large value/ scaling down larger range value into small range(eg:1cm:1kg)
#standard deviation : σ = √[∑(x - μ)² / N]
#xstand : (x-mean(x))/(s.d(x))

#1. Standard Scaler
df3=df2.copy()
from sklearn.preprocessing import StandardScaler
ssc = StandardScaler()
df2[['Age','Salary']] = ssc.fit_transform(df2[['Age','Salary']])
df2

#2. MinMax Scaler/ Normalization (changes value into 0-1 range)
#xnorm: (x-min(x))/(max(x)-min(x))

from sklearn.preprocessing import MinMaxScaler
scaler=MinMaxScaler()
df3[['Age','Salary']] = scaler.fit_transform(df3[['Age','Salary']])
df3

