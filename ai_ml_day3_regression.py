# -*- coding: utf-8 -*-
"""AI/ML_Day3_Regression.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1MJ9LZErO93RrIIZZNOn9Lm2g0zgELMOq
"""

#step 1: import Libraries
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

#Step 2: Load dataset
df=pd.read_csv('/salary_data.csv')
df

#Step 3: EDA
df.head()

df.tail()

df.corr() #correlation matrix (Positive correlation: As one variable increases, the other also increases (e.g., height and weight), Negative correlation: As one variable increases, the other decreases (e.g., price of a product and quantity demanded).
#)No correlation: There is no discernible relationship between the variables

#Checking is null value
df.isnull().sum()

#imputation

#from sklearn.impute import SimpleImputer
#imputer = SimpleImputer(missing_values=np.nan,strategy= 'mean')
#imputer.fit(df[['Experience','Salary']])
#df[['Experience','Salary']] = imputer.transform(df[['Experience','Salary']])
#df

df.duplicated().sum()

#df.drop_duplicates(inplace= True)
#df  (beacuse the same age person can have the same salary)

sns.boxplot(df['YearsExperience'])

sns.boxplot(df['Salary'])

#no outliers in in Experience ,salary
#Outliers removal needed
#label encoding -not required (beacuse there is no text value)
#sacling - not required (beacuse values may be small value later plotting will be crucial)

#Linear Regression
#TRAIN TEST SPLIT

from sklearn.model_selection import train_test_split #Function
#Define X,Y
#X= df[['Experience]]
#Y= df[['Salary]]

X=df.drop('Salary',axis=1)
y=df['Salary']
#Split the data into training and testing sets
X_train,X_test,y_train,y_test= train_test_split(X,y,test_size=0.2,random_state=42) #test size means percentage of test data random_state means arameter in train_test_split that controls the random number generator used to shuffle the data before splitting it.

print(df.shape) #Shape of the dataset
print(X.shape) #Shape of the Target variable
print(y.shape) #shape of the Dependent variable
#20% Testing 75, Training (80%): 298
print(X_train.shape) # X train shape
print(X_test.shape) # X test shape
print(y_train.shape) # y train shape
print(y_test.shape) #y test shape

#Model Selection and Training
#Model: Linear Regression Model(we going to make the prediction using linear algorithm)
from sklearn.linear_model import LinearRegression
model= LinearRegression() #object Creation
model.fit(X_train,y_train) #fit is used to train the model

X_test #x_test data

#Make predicition on the test data

y_pred=model.predict(X_test)
y_pred #predicted test

y_test #answer key

#MODEL EVALUATION
# 10 - 11  = Error = abs|-1| = 1  = y1 - y^1
# 15 - 14  = Error = abs +1 = y2 - y^2
# 9  - 11    Errp = |-2| = 2 = y3 - y^3
# 8  - 6    -=      = abs 2 = y4 - y^4

#Sum(|yi - y^i|)/n

# Total Error = -1 + 1 -2 + 2 = 0
# Total Absoulute Error = 1 + 1 +2 + 2 = 6
#Means Absoulute Error = 6/4  MAE

# -ve to +ve
# 10 - 11  = Error = sqare(-1) = 1
# 15 - 14  = Error = sqare( +1) = 1
# 9  - 11    Errp =sqare(-2) = 4
# 8  - 6    -=      = sqare( -2) = 4
# Total Square Error = 1 + 1 +4 +4 = 10
# Mean Squared Error = 10/4  MSE
# Root Mean Squared Error = sqrt(MSE) =

from sklearn.metrics import mean_absolute_error
# Evaluate the model
mae = mean_absolute_error(y_test, y_pred)
print(f'Mean Absolute Error: {mae}')

from sklearn.metrics import mean_squared_error
mse = mean_squared_error(y_test, y_pred) #answer key, answersheet - evaluate
print(f'Mean Squared Error: {mse}')

from sklearn.metrics import root_mean_squared_error
# Evaluate the model
rmse =root_mean_squared_error(y_test, y_pred)
print(f'Root Mean Squared Error: {rmse}')

from sklearn.metrics import r2_score
# Evaluate the model using R-squared
r2 = r2_score(y_test, y_pred)
print(f'R-squared: {r2}')

#Extract Coefficient
slope=model.coef_[0] #slope value
intercept = model.intercept_ #y intercept (c)

# Display intercepts
print(f'Slope: {slope}')
print(f'Y-Intercept: {intercept}')
print(f'X-Intercept: {-intercept/slope}')

# Plot the original data and the regression line
plt.scatter(X_test, y_test, color='black', label='Actual data')
plt.plot(X_test, y_pred, color='blue', linewidth=1, label='Regression line',marker='*')
plt.xlabel('Experience')
plt.ylabel('Salary')
plt.title('Linear Regression on Salary Data')
plt.legend()
plt.show()

