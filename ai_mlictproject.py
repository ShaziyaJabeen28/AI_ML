# -*- coding: utf-8 -*-
"""AI/MLictProject.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/10vJzDClabJOlsEG1fMCliVQNXwev5xyG
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

df=pd.read_csv('https://raw.githubusercontent.com/tech4alltraining/aiml/refs/heads/main/datasets/classification/project/credit_score.csv')
df

"""This is a classification problem.  The Goal is to Build a machine learning system to classify people into credit score brackets.

Independent variables (features): credit_score

*   List item


 Dependent variables (target): Month,Age,Occupation  Annual_Income  Monthly_Inhand_Salary  Num_Bank_Accounts  Num_Credit_Card  Interest_Rate  Num_of_Loan  Type_of_Loan  Delay_from_due_date  Num_of_Delayed_Payment  Changed_Credit_Limit  Num_Credit_Inquiries  Credit_Mix  Outstanding_Debt  Credit_Utilization_Ratio  Credit_History_Age  Payment_of_Min_Amount  Total_EMI_per_month  Amount_invested_monthly  Payment_Behaviour  Monthly_Balance
 No need :ID,Customer_ID,Name,SSN

Exploratory Data Analysis (EDA) -
Determine the number of rows and columns:
"""

df.info()

df.shape[0]   #No of rows

df.shape[1]   #No of columns

df.shape

#Show the data types of each column:
df.dtypes

#summary statistics
df.describe()

# Columns that should be integers
int_columns = [
    'Age',
    'Num_Bank_Accounts',
    'Num_Credit_Card',
    'Interest_Rate',
    'Num_of_Loan',
    'Delay_from_due_date',
    'Num_of_Delayed_Payment',
    'Num_Credit_Inquiries'
]

# Other numeric columns that should be floats
float_columns = [
    'Annual_Income',
    'Changed_Credit_Limit',
    'Outstanding_Debt',
    'Amount_invested_monthly',
    'Monthly_Balance'
]

# Function to clean and convert
def clean_numeric(series):
    return pd.to_numeric(
        series.astype(str)               # ensure string
              .str.replace(r'[^\d\.-]', '', regex=True),  # remove non-numeric chars
        errors='coerce'
    )

# Convert integer columns
for col in int_columns:
    df[col] = clean_numeric(df[col]).astype('Int64')  # nullable int

# Convert float columns
for col in float_columns:
    df[col] = clean_numeric(df[col]).astype('float64')

# Check result
print(df[int_columns + float_columns].dtypes)

# Numerical features
num_features = df.select_dtypes(include=[np.number]).columns.tolist()
print("Numerical Features:", num_features)
print("Count of Numerical Features:", len(num_features))

# Categorical features
cat_features = df.select_dtypes(exclude=[np.number]).columns.tolist()
print("Categorical Features:", cat_features)
print("Count of Categorical Features:", len(cat_features))

# Display distinct values for each categorical feature
for col in cat_features:
    print(f"Distinct values in '{col}':")
    print(df[col].unique())
    print(f"Count: {df[col].nunique()}\n")

#Bar graph of any three features
features = ['Occupation', 'Credit_Mix', 'Payment_Behaviour']

plt.figure(figsize=(18, 5))

for i, feature in enumerate(features, 1):
    plt.subplot(1, 3, i)

    # Get counts of each category
    counts = df[feature].value_counts()

    # Bar chart
    plt.bar(counts.index, counts.values, color='g')
    plt.title(f'Distribution of {feature}')
    plt.xticks(rotation=45)
    plt.ylabel('Count')

plt.tight_layout()
plt.show()

#corelation : how to relate one column to another column

df.select_dtypes(include=np.number).corr()

#Heat map : graphical representaion of correlation
sns.heatmap(df.select_dtypes(include=np.number).corr())

# Select numerical features to examine
num_features_to_plot = ['Annual_Income', 'Outstanding_Debt', 'Credit_Utilization_Ratio']

# Plot histograms
df[num_features_to_plot].hist(figsize=(15, 5), bins=20, color='skyblue', edgecolor='black')
plt.suptitle('Distribution of Selected Numerical Features', fontsize=16)
plt.show()

#Data Processing
#Handle missing values
# Check missing values in each column
print(df.isnull().sum())

df.drop(['ID', 'Customer_ID', 'Name', 'SSN'], axis=1, inplace=True)
#unwanted columns

from sklearn.impute import SimpleImputer
imputer = SimpleImputer(missing_values=np.nan, strategy='mean')
imputer.fit(df[['Monthly_Balance','Amount_invested_monthly','Changed_Credit_Limit','Num_of_Delayed_Payment','Monthly_Inhand_Salary','Num_Credit_Inquiries']])
df[['Monthly_Balance','Amount_invested_monthly','Changed_Credit_Limit','Num_of_Delayed_Payment','Monthly_Inhand_Salary','Num_Credit_Inquiries']]= imputer.transform(df[['Monthly_Balance','Amount_invested_monthly','Changed_Credit_Limit','Num_of_Delayed_Payment','Monthly_Inhand_Salary','Num_Credit_Inquiries']])
df

print(df.isnull().sum())

from sklearn.impute import SimpleImputer
imputer1 = SimpleImputer(missing_values=np.nan, strategy='most_frequent')
imputer1.fit(df[['Credit_History_Age','Type_of_Loan']])
df[['Credit_History_Age','Type_of_Loan']]= imputer1.transform(df[['Credit_History_Age','Type_of_Loan']])
df

print(df.isnull().sum())

#check duplicates
df.duplicated().sum()

#Outliers (Values outside the defined range) we use box plot to check outliers
sns.boxplot(df['Age'])

q1, q3 = np.percentile(df['Age'], [25, 75])
iqr = q3-q1
lower_bound = q1 - (1.5 * iqr)
upper_bound = q3 + (1.5 * iqr)
print(lower_bound, upper_bound)
df = df[(df['Age'] >= lower_bound)  & (df['Age'] <= upper_bound)]
df

sns.boxplot(df['Annual_Income'])

sns.boxplot(df['Monthly_Inhand_Salary'])

q1, q3 = np.percentile(df['Monthly_Inhand_Salary'], [25, 75])
iqr = q3-q1
lower_bound = q1 - (1.5 * iqr)
upper_bound = q3 + (1.5 * iqr)
print(lower_bound, upper_bound)
df = df[(df['Monthly_Inhand_Salary'] >= lower_bound)  & (df['Monthly_Inhand_Salary'] <= upper_bound)]
df

sns.boxplot(df['Num_Bank_Accounts'])

sns.boxplot(df['Num_Credit_Card'])

sns.boxplot(df['Interest_Rate'])

sns.boxplot(df['Num_of_Loan' ])

q1, q3 = np.percentile(df['Num_of_Loan'], [25, 75])
iqr = q3-q1
lower_bound = q1 - (1.5 * iqr)
upper_bound = q3 + (1.5 * iqr)
print(lower_bound, upper_bound)
df = df[(df['Num_of_Loan'] >= lower_bound)  & (df['Num_of_Loan'] <= upper_bound)]
df

sns.boxplot(df['Delay_from_due_date' ])

q1, q3 = np.percentile(df['Delay_from_due_date'], [25, 75])
iqr = q3-q1
lower_bound = q1 - (1.5 * iqr)
upper_bound = q3 + (1.5 * iqr)
print(lower_bound, upper_bound)
df = df[(df['Delay_from_due_date'] >= lower_bound)  & (df['Delay_from_due_date'] <= upper_bound)]
df

sns.boxplot(df['Num_of_Delayed_Payment'])

sns.boxplot(df['Changed_Credit_Limit' ])

q1, q3 = np.percentile(df['Changed_Credit_Limit'], [25, 75])
iqr = q3-q1
lower_bound = q1 - (1.5 * iqr)
upper_bound = q3 + (1.5 * iqr)
print(lower_bound, upper_bound)
df = df[(df['Changed_Credit_Limit'] >= lower_bound)  & (df['Changed_Credit_Limit'] <= upper_bound)]
df

sns.boxplot(df['Num_Credit_Inquiries'])

sns.boxplot(df['Outstanding_Debt'])

q1, q3 = np.percentile(df['Outstanding_Debt'], [25, 75])
iqr = q3-q1
lower_bound = q1 - (1.5 * iqr)
upper_bound = q3 + (1.5 * iqr)
print(lower_bound, upper_bound)
df = df[(df['Outstanding_Debt'] >= lower_bound)  & (df['Outstanding_Debt'] <= upper_bound)]
df

sns.boxplot(df['Credit_Utilization_Ratio'])

sns.boxplot(df['Total_EMI_per_month'])

sns.boxplot(df['Amount_invested_monthly'])

q1, q3 = np.percentile(df['Amount_invested_monthly'], [25, 75])
iqr = q3-q1
lower_bound = q1 - (1.5 * iqr)
upper_bound = q3 + (1.5 * iqr)
print(lower_bound, upper_bound)
df = df[(df['Amount_invested_monthly'] >= lower_bound)  & (df['Amount_invested_monthly'] <= upper_bound)]
df

sns.boxplot(df['Monthly_Balance'])

q1, q3 = np.percentile(df['Monthly_Balance'], [25, 75])
iqr = q3-q1
lower_bound = q1 - (1.5 * iqr)
upper_bound = q3 + (1.5 * iqr)
print(lower_bound, upper_bound)
df = df[(df['Monthly_Balance'] >= lower_bound)  & (df['Monthly_Balance'] <= upper_bound)]
df

df.head()

from sklearn.preprocessing import LabelEncoder
le = LabelEncoder()
df['Month'] = le.fit_transform(df['Month'])
df['Occupation'] = le.fit_transform(df['Occupation'])
df['Credit_Mix'] = le.fit_transform(df['Credit_Mix'])
df['Payment_of_Min_Amount'] = le.fit_transform(df['Payment_of_Min_Amount'])
df['Type_of_Loan'] = le.fit_transform(df['Type_of_Loan'])
df['Credit_Score']= le.fit_transform(df['Credit_Score'])
df['Credit_History_Age']= le.fit_transform(df['Credit_History_Age'])
df['Payment_Behaviour']= le.fit_transform(df['Payment_Behaviour'])
df

from sklearn.preprocessing import StandardScaler
ssc = StandardScaler()
df[['Age', 'Annual_Income', 'Monthly_Inhand_Salary', 'Num_Bank_Accounts',
            'Num_Credit_Card', 'Interest_Rate', 'Num_of_Loan', 'Delay_from_due_date',
            'Num_of_Delayed_Payment', 'Changed_Credit_Limit', 'Num_Credit_Inquiries',
            'Outstanding_Debt', 'Credit_Utilization_Ratio', 'Total_EMI_per_month',
            'Amount_invested_monthly', 'Monthly_Balance']] = ssc.fit_transform(df[['Age', 'Annual_Income', 'Monthly_Inhand_Salary', 'Num_Bank_Accounts',
            'Num_Credit_Card', 'Interest_Rate', 'Num_of_Loan', 'Delay_from_due_date',
            'Num_of_Delayed_Payment', 'Changed_Credit_Limit', 'Num_Credit_Inquiries',
            'Outstanding_Debt', 'Credit_Utilization_Ratio', 'Total_EMI_per_month',
            'Amount_invested_monthly', 'Monthly_Balance']])
df

#Splitting data
from sklearn.model_selection import train_test_split
# Features (all columns except target)
X = df.drop('Credit_Score', axis=1)

# Target column
y = df['Credit_Score']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

print("Training set size:", X_train.shape)
print("Test set size:", X_test.shape)

1.#Model Selection Training - Logistic Regression(A classification algorithm)
from sklearn.linear_model import LogisticRegression  #class  import
lr = LogisticRegression() #object / instance creation
lr.fit(X_train, y_train) # Training

#The model didnâ€™t converge within the default max_iter=100 iterations.

#Logistic regression uses an optimization algorithm (lbfgs by default).

#If the data is complex, the solver might need more iterations.

from sklearn.linear_model import LogisticRegression  #class  import
lr = LogisticRegression(max_iter=1000, solver='lbfgs') #object / instance creation
lr.fit(X_train, y_train)

from sklearn.linear_model import LogisticRegression  #class  import
lr = LogisticRegression(max_iter=1000, solver='liblinear') #object / instance creation
lr.fit(X_train, y_train)

y_pred = lr.predict(X_test) #Evaluation
y_pred

from sklearn.metrics import confusion_matrix, classification_report, accuracy_score
print(confusion_matrix(y_test, y_pred))
print(classification_report(y_test, y_pred))
print(accuracy_score(y_test, y_pred))

# prompt: plot confusion matrix*
import matplotlib.pyplot as plt
cm = confusion_matrix(y_test, y_pred)
plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False,
            xticklabels=le.classes_, yticklabels=le.classes_)
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.title('Confusion Matrix')
plt.show()

2.#Selected Model- kNN
from sklearn.neighbors import KNeighborsClassifier
knn = KNeighborsClassifier(n_neighbors=5)
knn.fit(X_train, y_train)

y_pred = knn.predict(X_test)
y_pred

print(accuracy_score(y_test, y_pred))
print(confusion_matrix(y_test, y_pred))
print(classification_report(y_test, y_pred))

# prompt: plot confusion matrix*
import matplotlib.pyplot as plt
cm = confusion_matrix(y_test, y_pred)
plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False,
            xticklabels=le.classes_, yticklabels=le.classes_)
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.title('Confusion Matrix')
plt.show()

